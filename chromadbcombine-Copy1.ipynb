{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8aee245c-087a-4199-a341-aff27d9b3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.llms import Ollama\n",
    "import chromadb\n",
    "import fitz\n",
    "import regex as re\n",
    "import uuid\n",
    "# from chromadb.api import HttpClient\n",
    "response_strings=[]\n",
    "\n",
    "def fitz_extract_text(pdf_file_path):\n",
    "    all_text = []\n",
    "    doc = fitz.open(pdf_file_path)\n",
    "    page_count = doc.page_count\n",
    "    for page_num in range(page_count):\n",
    "        page = doc[page_num]\n",
    "        text = page.get_text()\n",
    "        # text = page.get_text().replace('\\n',' ')\n",
    "        all_text.append(text)\n",
    "\n",
    "    return all_text\n",
    "\n",
    "def retrieve_and_generate(query, logfile):\n",
    "    try:\n",
    "        query_embedding = embedding_model.encode([query]).tolist()\n",
    "        top_k = 1\n",
    "        results = collectionIds.query(query_embedding, n_results=top_k)\n",
    "        most_relevant_document = results['documents'][0]\n",
    "\n",
    "        response = llm_model.generate(\n",
    "            prompts=[f\"Query: {query}\\nDocument: {most_relevant_document}\\nResponse:\"]\n",
    "        )\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        lineno = tb.tb_lineno\n",
    "        ob = f'\\nIn LLM Time: {datetime.now()} \\nLINE.NO-{lineno} : {exc_obj}'\n",
    "        with open(logfile, 'a', encoding='utf-8') as fp:\n",
    "            fp.writelines(ob)\n",
    "\n",
    "\n",
    "def processFile(all_text, logfile):\n",
    "    print(\"processFile\")\n",
    "    try:\n",
    "        embeddings = embedding_model.encode(all_text).tolist()\n",
    "        # documents = [{\"text\": text, \"embedding\": embedding} for text, embedding in zip(all_text, embeddings)]\n",
    "        documentsList = []\n",
    "        embeddingList = []\n",
    "        idsList = []\n",
    "        n = 1\n",
    "        for text, embedding in zip(all_text, embeddings):\n",
    "            documentsList.append(text)\n",
    "            embeddingList.append(embedding)\n",
    "            idsList.append(\"ids\" + str(n))\n",
    "            n += 1\n",
    "        collectionIds.add(documents=documentsList, embeddings=embeddingList, ids=idsList)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"error=>processFile=>\", e)\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        lineno = tb.tb_lineno\n",
    "        ob = f'\\nIn LLM Time: {datetime.now()} \\nLINE.NO-{lineno} : {exc_obj}'\n",
    "        with open(logfile, 'a', encoding='utf-8') as fp:\n",
    "            fp.writelines(ob)\n",
    "\n",
    "\n",
    "def processPrompt(all_text, prompt, logfile):\n",
    "    try:\n",
    "        all_texts=[]\n",
    "        text_to_pageNumber = {text: i for i, text in enumerate(all_text)}\n",
    "\n",
    "        query_embedding = embedding_model.encode([prompt]).tolist()\n",
    "        top_k = 1\n",
    "        results = collectionIds.query(query_embedding, n_results=top_k)\n",
    "        # print(results)\n",
    "        most_relevant_document = results['documents'][0]\n",
    "        page_number = (results['ids'][0][0]).split(\"ids\")[1]\n",
    "        # print(page_number)\n",
    "        # page_number = text_to_pageNumber[most_relevant_document]\n",
    "\n",
    "        response_text = llm_model.generate(\n",
    "            prompts=[f\"Query: {prompt}\\nDocument: {most_relevant_document}\\nResponse:\"]\n",
    "        )\n",
    "        for generation_chunk in response_text.generations:\n",
    "            for generation in generation_chunk:\n",
    "                # all_texts.append(generation.text)\n",
    "                pattern = r'{(?:[^{}]*|(?R))*}'\n",
    "       \n",
    "                json_text_match = re.search(pattern, generation.text, re.DOTALL)\n",
    "                \n",
    "                if json_text_match:\n",
    "                    # print(json_text_match.group())\n",
    "                    data_dict=json.loads(json_text_match.group().replace(\"'\",'\"'))\n",
    "                    all_texts.append(data_dict)\n",
    "        return all_texts\n",
    "        # clean_data = str(response_text).replace('`', '')\n",
    "        # if re.search(r'{.*}\\\\n', clean_data):\n",
    "        #     data = re.search(r'{.*}\\\\n', clean_data).group(0)\n",
    "        #     clean_data = data.replace('\\n', '').replace('\\\\n', '').replace('\\\\', '')\n",
    "        #     data_dict = json.loads(clean_data)\n",
    "        #     final_response = {'Page': page_number + 1}\n",
    "        #     for key, value in data_dict.items():\n",
    "        #         final_response[key] = value\n",
    "        #     return final_response\n",
    "        # else:\n",
    "        #     return \"Data not found\"\n",
    "    except Exception as e:# Initialize ChromaDB client\n",
    "        \n",
    "        # Replace with your ChromaDB server URL\n",
    "        print(\"error=>\", e)\n",
    "        exc_type, exc_obj, tb = sys.exc_info()\n",
    "        lineno = tb.tb_lineno\n",
    "        ob = f'\\nIn LLM Time: {datetime.now()} \\nLINE.NO-{lineno} : {exc_obj}'\n",
    "        with open(logfile, 'a', encoding='utf-8') as fp:\n",
    "            fp.writelines(ob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11069a98-7c8e-4814-812f-e852bc01a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logfile = 'log.txt'\n",
    "pdf_file_path = r'pdf/PeterbiltIllinoisVJ.pdf'\n",
    "all_text = fitz_extract_text(pdf_file_path)\n",
    "\n",
    "# Initialize models\n",
    "llm_model = Ollama(model=\"llama3:instruct\", temperature=0)\n",
    "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_model = Ollama(model='nomic-embed-text',temperature=0)\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Replace with your ChromaDB server URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0e563a4-224c-47bc-a8bc-dfd03e2d1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuidName=str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5291b01-ec91-4d69-83af-090c948a00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in [chromaName.name for chromaName in chroma_client.list_collections()]:\n",
    "#     chroma_client.delete_collection(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34ab5b73-e6f4-44ce-a736-a948ada8e4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE\n",
      "ba4936e2-9933-4952-ad13-3325ea681722\n"
     ]
    }
   ],
   "source": [
    "fileName = 'PeterbiltIllinoisVJ3'\n",
    "# Replace your collection name and settings accordingly\n",
    "collection_tableName = \"TableCollection\"\n",
    "collectionTable = chroma_client.get_or_create_collection(name=collection_tableName)\n",
    "\n",
    "index = 0\n",
    "if not fileName in [doc for doc in collectionTable.get()['documents']]:\n",
    "    collectionTable.add(documents=[fileName], ids=[uuidName])\n",
    "\n",
    "for doc in collectionTable.get()['documents']:\n",
    "    if fileName == doc:\n",
    "        # collectionTable.update(documents=[fileName],ids=[idsList for idsList in collectionTable.get(include=['documents'])]])\n",
    "        print(\"TRUE\")\n",
    "        break\n",
    "    index += 1\n",
    "print(collectionTable.get()['ids'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "557901a4-c552-4438-9836-2747aa70c3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TableCollection', 'ba4936e2-9933-4952-ad13-3325ea681722']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print([chromaName.name for chromaName in chroma_client.list_collections()])\n",
    "isCreate = collectionTable.get()['ids'][index] in [chromaName.name for chromaName in chroma_client.list_collections()]\n",
    "print(isCreate)\n",
    "if isCreate:\n",
    "    collectionIds = chroma_client.get_collection(name=collectionTable.get()['ids'][index])\n",
    "else:\n",
    "    collectionIds = chroma_client.create_collection(name=collectionTable.get()['ids'][index])\n",
    "# print(collectionTable.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b63b1772-7812-478f-bff9-26d0330f6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isCreate:\n",
    "    processFile(all_text, logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "997e6c9e-2d46-471a-b634-061b418fe526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2024-07-04 10:26:33.518695\n",
      "error=> 'Ollama' object has no attribute 'encode'\n",
      "end 2024-07-04 10:26:33.520667\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print('start',datetime.now())\n",
    "prompt = \"Extract the landlord address like {'landlordStreetAddress1':'','landlordStreetAddress2':'','City':'','State':'','Zipcode':''}\"\n",
    "result = processPrompt(all_text, prompt, logfile)\n",
    "print('end',datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bb551ea-440c-46c2-9a27-2bb5001d1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfe9d25a-5378-4282-8640-bb48f89daa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import chromadb\n",
    "import uuid\n",
    "import faiss\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "config_data = json.loads(open(\"config.json\", \"r+\").read())\n",
    "RAG = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "chroma_client = chromadb.Client()\n",
    "collection_tableName = config_data[\"tableName\"]\n",
    "collectionTable = chroma_client.get_or_create_collection(name=collection_tableName)\n",
    "fileName=\"summary records sample.pdf\"\n",
    "all_text=json.loads(open(f\"all_context{fileName.split('.pdf')[0]}.json\",\"r+\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da428d92-f124-4990-90e0-6801adcc8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"where is the vitals reports?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f88b4b8d-445a-414a-86a6-a0d4045ac945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['578a793c-89bf-4bba-a79b-0cdb1654d5a9'], 'embeddings': None, 'documents': ['summary records sample.pdf'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [None]}\n",
      "578a793c-89bf-4bba-a79b-0cdb1654d5a9\n",
      "after\n",
      "{'ids': [], 'embeddings': None, 'documents': [], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': []}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# delete\n",
    "get_collection=collectionTable.get()\n",
    "print(get_collection)\n",
    "doc_list=get_collection[\"documents\"]\n",
    "ids_list=get_collection[\"ids\"]\n",
    "for i in range(len(doc_list)):\n",
    "    print(ids_list[i])\n",
    "    collectionTable.delete(ids=[ids_list[i]])\n",
    "print(\"after\")\n",
    "\n",
    "print(collectionTable.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cfe1acb4-ca3b-4302-9a4f-af0217454a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text splitter\n",
    "import re\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "total_chunks=RecursiveCharacterTextSplitter(separators=\"\\n\",chunk_overlap=5)\n",
    "all_chunks=[]\n",
    "for context in all_text:\n",
    "    chunk=total_chunks.split_text(re.sub(\"\\s+\",\" \",context))\n",
    "    all_chunks.extend(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6feccab6-0a50-485d-a3f4-a55392da0e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['3f278492-4924-46ce-b679-89dd98442f7b'], 'embeddings': None, 'documents': ['summary records sample.pdf'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [None]}\n",
      "[0]\n",
      "True\n",
      "['values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 24 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 12 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 9 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 22 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 1 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 2 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 30 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 23 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 7 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 25 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 16 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n', 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 4 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n']\n",
      "total chromadb time:0:00:00.002957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "top_k = int(len(all_chunks) * 0.2)\n",
    "embeddings = RAG.encode(all_chunks, convert_to_numpy=True)\n",
    "q_emb = RAG.encode([query], convert_to_numpy=True)\n",
    "uuidName = str(uuid.uuid4())\n",
    "print(collectionTable.get())\n",
    "doc_list=collectionTable.get()[\"documents\"]\n",
    "ids_list=collectionTable.get()[\"ids\"]\n",
    "index_list= [i for i,data in enumerate(doc_list) if data==fileName]\n",
    "if index_list:\n",
    "    print(index_list)\n",
    "    start=datetime.now()\n",
    "    for index in index_list:\n",
    "        isCreate = ids_list[index] in [chromaName.name for chromaName in chroma_client.list_collections()]\n",
    "        print(isCreate)\n",
    "        if isCreate:\n",
    "            collectionIds = chroma_client.get_collection(name=ids_list[index])\n",
    "        else:\n",
    "            collectionIds = chroma_client.create_collection(name=ids_list[index])\n",
    "        idsList = [\"ids\" + str(n) for n in range(len(all_text))]\n",
    "        results = collectionIds.query(q_emb, n_results=top_k)\n",
    "        print(results['documents'][0])\n",
    "    end=datetime.now()\n",
    "    print(f\"total chromadb time:{end-start}\")\n",
    "else:\n",
    "    start=datetime.now()\n",
    "    index_ = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index_.add(embeddings)\n",
    "    D, I = index_.search(q_emb, k=top_k)\n",
    "    chunk_list = [all_text[i] for i in I[0]]\n",
    "    embed_list = [embeddings[i] for i in I[0]]\n",
    "    collectionTable.add(documents=[fileName], ids=[uuidName])\n",
    "    index= [i for i,data in enumerate(collectionTable.get()[\"documents\"]) if data==fileName][0]\n",
    "    collectionIds = chroma_client.create_collection(name=collectionTable.get()['ids'][index])\n",
    "    idsList = [\"ids\" + str(n) for n in range(len(chunk_list))]\n",
    "    collectionIds.add(embeddings=embed_list, ids=idsList, documents=chunk_list)\n",
    "    results = collectionIds.query(q_emb, n_results=top_k)\n",
    "    end=datetime.now()\n",
    "    print(f\"total RAG time:{end-start}\")\n",
    "    print(results['documents'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "430f49b8-81d4-4918-aa54-9336d9a9b815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['7113a4d7-8af4-49a1-a817-b35f94dddd74'], 'embeddings': None, 'documents': ['summary records sample.pdf'], 'uris': None, 'included': ['metadatas', 'documents'], 'data': None, 'metadatas': [None]}\n",
      "TRUE\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 24 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 12 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 9 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 22 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 1 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 2 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 30 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 23 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 7 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 25 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 16 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n',\n",
       " 'values, identifiers, dates, or findings across the entire medical record set. Each section has been\\nintentionally expanded to provide comprehensive clinical context.\\nSummary\\nAppointment 4 documents an independent medical evaluation with individualized history,\\ndiagnostics, assessment, and observations. The encounter concludes with conservative\\nmanagement recommendations and plans for follow-up as needed.\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "# top_k = int(len(all_chunks) * 0.2)\n",
    "# embeddings = RAG.encode(all_chunks, convert_to_numpy=True)\n",
    "# q_emb = RAG.encode([query], convert_to_numpy=True)\n",
    "# uuidName = str(uuid.uuid4())\n",
    "# collectionTable.add(documents=[fileName], ids=[uuidName])\n",
    "# index = 0\n",
    "# print(collectionTable.get())\n",
    "# doc_list=collectionTable.get()[\"documents\"]\n",
    "# ids_list=collectionTable.get()[\"ids\"]\n",
    "# for i in range(len(doc_list)):\n",
    "#     if fileName == doc_list[i]:\n",
    "#         collectionTable.update(documents=[fileName],ids=[ids_list[i]])\n",
    "#         index=i\n",
    "#         print(\"TRUE\")\n",
    "#         break\n",
    "# print(index)\n",
    "# isCreate = collectionTable.get()['ids'][index] in [chromaName.name for chromaName in\n",
    "#                                                    chroma_client.list_collections()]\n",
    "# if isCreate:\n",
    "#     collectionIds = chroma_client.get_collection(name=collectionTable.get()['ids'][index])\n",
    "# else:\n",
    "#     collectionIds = chroma_client.create_collection(name=collectionTable.get()['ids'][index])\n",
    "\n",
    "# idsList = [\"ids\" + str(n) for n in range(len(all_text))]\n",
    "# collectionIds.add(embeddings=embeddings, ids=idsList, documents=all_text)\n",
    "# results = collectionIds.query(q_emb, n_results=top_k)\n",
    "# results['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3480a706-55e1-43eb-8deb-311d5c17fb52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ca63ffc-29d2-47f0-9931-a66373f2bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\\n\".join(all_text)\n",
    "with open(\"ttxt.txt\",\"w+\")as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f050cf4-2a49-4e4d-8894-db7d5e34427b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
